
#!/usr/bin/env python3
"""
manage_ai_models.py - Narzƒôdzie do zarzƒÖdzania modelami AI w ≈õrodowisku lokalnym
"""

import os
import sys
import argparse
import logging
from datetime import datetime

# Dodanie ≈õcie≈ºek do PYTHONPATH
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)
python_libs_dir = os.path.join(current_dir, "python_libs")
sys.path.append(python_libs_dir)

# Konfiguracja logowania
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)

def list_models():
    """Wy≈õwietla listƒô dostƒôpnych modeli AI."""
    try:
        from ai_models.model_recognition import ModelRecognizer
        recognizer = ModelRecognizer()
        models = recognizer.scan_models()
        
        if not models:
            logger.info("Nie znaleziono ≈ºadnych modeli AI.")
            return
        
        logger.info(f"Znaleziono {len(models)} modeli AI:")
        for idx, model in enumerate(models, 1):
            status = model.get("status", "Nieznany")
            status_symbol = "‚úÖ" if status == "Active" else "‚ùå" if status == "Error" else "‚ùì"
            logger.info(f"{idx}. {status_symbol} {model['name']} ({model.get('type', 'Nieznany')}) - Dok≈Çadno≈õƒá: {model.get('accuracy', 'N/A')}%")
    
    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas wy≈õwietlania modeli: {e}")

def test_model(model_name=None):
    """Testuje okre≈õlony model AI."""
    try:
        from ai_models.model_recognition import ModelRecognizer
        from python_libs.model_tester import ModelTester
        
        tester = ModelTester(models_path='ai_models', log_path='logs/model_tests.log')
        
        if model_name:
            logger.info(f"Testowanie modelu: {model_name}")
            result = tester.test_model(model_name)
            if result["success"]:
                logger.info(f"Test zako≈Ñczony pomy≈õlnie. Dok≈Çadno≈õƒá: {result.get('accuracy', 'N/A')}%")
            else:
                logger.error(f"Test nie powi√≥d≈Ç siƒô: {result.get('error', 'Nieznany b≈ÇƒÖd')}")
        else:
            logger.info("Testowanie wszystkich modeli...")
            results = tester.run_tests()
            logger.info(f"Testy zako≈Ñczone. Wyniki: {len(results)} modeli przetestowano.")
            
            # Wy≈õwietlanie wynik√≥w
            for model_name, result in results.items():
                status = "‚úÖ Sukces" if result.get("success", False) else "‚ùå B≈ÇƒÖd"
                logger.info(f"{model_name}: {status} - Dok≈Çadno≈õƒá: {result.get('accuracy', 'N/A')}%")
    
    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas testowania modeli: {e}")

def main():
    """Funkcja g≈Ç√≥wna."""
    parser = argparse.ArgumentParser(description="Narzƒôdzie do zarzƒÖdzania modelami AI")
    parser.add_argument("--list", action="store_true", help="Wy≈õwietl listƒô dostƒôpnych modeli")
    parser.add_argument("--test", action="store_true", help="Uruchom testy modeli")
    parser.add_argument("--model", type=str, help="Okre≈õlony model do przetestowania")
    
    args = parser.parse_args()
    
    if args.list:
        list_models()
    elif args.test:
        test_model(args.model)
    else:
        parser.print_help()

if __name__ == "__main__":
    logger.info("Narzƒôdzie zarzƒÖdzania modelami AI")
    main()
#!/usr/bin/env python3
"""
manage_ai_models.py
------------------
Narzƒôdzie CLI do zarzƒÖdzania modelami AI: przeglƒÖdanie, czyszczenie, retrenowanie
i monitorowanie ich wydajno≈õci.
"""

import os
import argparse
import json
import logging
import time
from datetime import datetime
from typing import Dict, Any, List, Optional

# Konfiguracja logowania
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger("ai_models_manager")

try:
    from ai_models.model_utils import (
        list_available_models, 
        save_model, 
        load_model,
        create_model_checkpoint,
        ensure_model_dirs
    )
except ImportError:
    logger.error("Nie mo≈ºna zaimportowaƒá modu≈Çu model_utils. Sprawd≈∫, czy plik istnieje i czy ≈õcie≈ºka jest poprawna.")
    # Fallback do podstawowych funkcji
    def ensure_model_dirs():
        os.makedirs("models", exist_ok=True)
        os.makedirs("saved_models", exist_ok=True)
    
    def list_available_models():
        models = []
        if os.path.exists("models"):
            for file in os.listdir("models"):
                if file.endswith(".pkl"):
                    models.append({
                        "name": file.replace(".pkl", ""),
                        "path": os.path.join("models", file),
                        "size": os.path.getsize(os.path.join("models", file)),
                        "last_modified": datetime.fromtimestamp(os.path.getmtime(os.path.join("models", file))).strftime("%Y-%m-%d %H:%M:%S")
                    })
        return models

def print_models_table(models: List[Dict[str, Any]]) -> None:
    """
    Wy≈õwietla tabelƒô z informacjami o modelach.
    
    Args:
        models: Lista modeli
    """
    if not models:
        print("Nie znaleziono modeli.")
        return
    
    # Przygotuj dane do wy≈õwietlenia
    headers = ["Nazwa", "Typ", "Rozmiar", "Ostatnia modyfikacja", "Accuracy"]
    rows = []
    
    for model in models:
        # Pobierz typ modelu z metadanych, je≈õli dostƒôpne
        model_type = model.get("metadata", {}).get("model_type", "Nieznany")
        
        # Pobierz accuracy z metadanych, je≈õli dostƒôpne
        accuracy = model.get("metadata", {}).get("accuracy", "N/A")
        if isinstance(accuracy, (int, float)):
            accuracy = f"{accuracy:.2f}%"
        
        # Sformatuj rozmiar
        size_kb = model["size"] / 1024
        if size_kb < 1024:
            size_str = f"{size_kb:.2f} KB"
        else:
            size_mb = size_kb / 1024
            size_str = f"{size_mb:.2f} MB"
        
        rows.append([
            model["name"],
            model_type,
            size_str,
            model["last_modified"],
            accuracy
        ])
    
    # Znajd≈∫ maksymalnƒÖ szeroko≈õƒá dla ka≈ºdej kolumny
    col_widths = [max(len(str(row[i])) for row in rows + [headers]) for i in range(len(headers))]
    
    # Wy≈õwietl nag≈Ç√≥wek
    header_row = " | ".join(f"{headers[i]:<{col_widths[i]}}" for i in range(len(headers)))
    print(header_row)
    print("-" * len(header_row))
    
    # Wy≈õwietl dane
    for row in rows:
        print(" | ".join(f"{str(row[i]):<{col_widths[i]}}" for i in range(len(headers))))

def create_model_backups() -> None:
    """Tworzy kopie zapasowe wszystkich modeli."""
    models = list_available_models()
    if not models:
        print("Nie znaleziono modeli do wykonania kopii zapasowej.")
        return
    
    print(f"Tworzenie kopii zapasowych {len(models)} modeli...")
    
    try:
        from python_libs.model_tester import ModelTester
        tester = ModelTester()
        backup_dir = os.path.join("saved_models", f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        os.makedirs(backup_dir, exist_ok=True)
        
        for model_info in models:
            model_name = model_info["name"]
            
            try:
                # Za≈Çaduj model
                model, metadata, success = load_model(model_name)
                
                if success and model is not None:
                    # Utw√≥rz kopiƒô zapasowƒÖ
                    import joblib
                    backup_path = os.path.join(backup_dir, f"{model_name}.pkl")
                    joblib.dump(model, backup_path)
                    
                    # Zapisz metadane
                    with open(os.path.join(backup_dir, f"{model_name}_metadata.json"), 'w') as f:
                        json.dump(metadata, f, indent=2)
                    
                    print(f"‚úÖ Utworzono kopiƒô zapasowƒÖ modelu {model_name} w {backup_path}")
                else:
                    print(f"‚ùå Nie uda≈Ço siƒô za≈Çadowaƒá modelu {model_name}")
            except Exception as e:
                print(f"‚ùå B≈ÇƒÖd podczas tworzenia kopii zapasowej modelu {model_name}: {e}")
        
        print(f"Kopie zapasowe zapisane w {backup_dir}")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd podczas tworzenia kopii zapasowych: {e}")

def test_all_models() -> None:
    """Testuje wszystkie dostƒôpne modele."""
    try:
        from python_libs.model_tester import ModelTester
        tester = ModelTester()
        results = tester.run_tests()
        
        print("\nüìä Wyniki test√≥w modeli:")
        for model_name, result in results.items():
            status = "‚úÖ" if result.get("predict_successful", False) else "‚ùå"
            accuracy = result.get("accuracy")
            accuracy_str = f"{accuracy:.2f}%" if isinstance(accuracy, (int, float)) else "N/A"
            
            print(f"{status} {model_name}: Accuracy: {accuracy_str}")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd podczas testowania modeli: {e}")

def retrain_selected_models(models_to_retrain: List[str], force: bool = False) -> None:
    """
    Trenuje wybrane modele.
    
    Args:
        models_to_retrain: Lista nazw modeli do przetrenowania
        force: Czy wymusiƒá przetrenowanie nawet je≈õli dane sƒÖ te same
    """
    try:
        from python_libs.model_tester import ModelTester
        tester = ModelTester()
        
        if not models_to_retrain or models_to_retrain[0].lower() == "all":
            # Trenuj wszystkie modele
            print("Rozpoczynam trening wszystkich modeli...")
            results = tester.run_tests(force_retrain=force)
        else:
            # Trenuj tylko wybrane modele
            results = {}
            for model_name in models_to_retrain:
                print(f"Rozpoczynam trening modelu {model_name}...")
                model_results = tester.test_model_by_name(model_name, force_retrain=force)
                results[model_name] = model_results
        
        print("\nüìù Wyniki treningu:")
        for model_name, result in results.items():
            fit_success = "‚úÖ" if result.get("fit_successful", False) else "‚ùå"
            fit_time = result.get("fit_time", 0)
            fit_time_str = f"{fit_time:.2f}s" if isinstance(fit_time, (int, float)) else "N/A"
            
            print(f"{fit_success} {model_name}: Czas treningu: {fit_time_str}")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd podczas trenowania modeli: {e}")

def show_model_details(model_name: str) -> None:
    """
    Wy≈õwietla szczeg√≥≈Çowe informacje o modelu.
    
    Args:
        model_name: Nazwa modelu
    """
    try:
        # Za≈Çaduj model i metadane
        model, metadata, success = load_model(model_name)
        
        if not success or model is None:
            print(f"‚ùå Nie uda≈Ço siƒô za≈Çadowaƒá modelu {model_name}")
            return
        
        print(f"\nüìã Szczeg√≥≈Çy modelu {model_name}:")
        print(f"Typ: {type(model).__name__}")
        print(f"Modu≈Ç: {type(model).__module__}")
        
        # Wy≈õwietl metadane, je≈õli dostƒôpne
        if metadata:
            print("\nMetadane:")
            for key, value in metadata.items():
                print(f"  {key}: {value}")
        else:
            print("\nBrak metadanych.")
        
        # Sprawd≈∫, czy model ma atrybuty, kt√≥re mogƒÖ byƒá interesujƒÖce
        if hasattr(model, 'get_params'):
            print("\nParametry modelu:")
            try:
                params = model.get_params()
                for key, value in params.items():
                    print(f"  {key}: {value}")
            except:
                print("  Nie uda≈Ço siƒô pobraƒá parametr√≥w.")
        
        # Sprawd≈∫, czy model ma atrybuty: feature_importances_, coef_, nebo classes_
        for attr in ['feature_importances_', 'coef_', 'classes_']:
            if hasattr(model, attr):
                print(f"\n{attr}:")
                try:
                    value = getattr(model, attr)
                    if hasattr(value, 'shape'):
                        print(f"  Kszta≈Çt: {value.shape}")
                    if hasattr(value, 'tolist'):
                        if value.size <= 20:  # Wy≈õwietl tylko niewielkie warto≈õci
                            print(f"  Warto≈õci: {value.tolist()}")
                        else:
                            print(f"  Pierwsze 5 warto≈õci: {value.flatten()[:5].tolist()}")
                    else:
                        print(f"  Warto≈õƒá: {value}")
                except:
                    print(f"  Nie uda≈Ço siƒô pobraƒá {attr}.")
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd podczas wy≈õwietlania szczeg√≥≈Ç√≥w modelu: {e}")

def main():
    # Upewnij siƒô, ≈ºe katalogi istniejƒÖ
    ensure_model_dirs()
    
    # Parser argument√≥w
    parser = argparse.ArgumentParser(description="Narzƒôdzie do zarzƒÖdzania modelami AI")
    subparsers = parser.add_subparsers(dest="command", help="Dostƒôpne komendy")
    
    # Komenda: list
    list_parser = subparsers.add_parser("list", help="Wy≈õwietla listƒô modeli")
    
    # Komenda: backup
    backup_parser = subparsers.add_parser("backup", help="Tworzy kopie zapasowe modeli")
    
    # Komenda: test
    test_parser = subparsers.add_parser("test", help="Testuje modele")
    
    # Komenda: retrain
    retrain_parser = subparsers.add_parser("retrain", help="Trenuje wybrane modele")
    retrain_parser.add_argument("models", nargs="*", default=["all"], help="Modele do przetrenowania (domy≈õlnie: all)")
    retrain_parser.add_argument("--force", action="store_true", help="Wymusza przetrenowanie nawet je≈õli dane sƒÖ te same")
    
    # Komenda: details
    details_parser = subparsers.add_parser("details", help="Wy≈õwietla szczeg√≥≈Çy modelu")
    details_parser.add_argument("model", help="Nazwa modelu")
    
    # Parsuj argumenty
    args = parser.parse_args()
    
    # Obs≈Çuga komend
    if args.command == "list" or not args.command:
        # Domy≈õlnie wy≈õwietl listƒô modeli
        models = list_available_models()
        print_models_table(models)
    elif args.command == "backup":
        create_model_backups()
    elif args.command == "test":
        test_all_models()
    elif args.command == "retrain":
        retrain_selected_models(args.models, args.force)
    elif args.command == "details":
        show_model_details(args.model)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
#!/usr/bin/env python
"""
manage_ai_models.py
------------------
Skrypt do zarzƒÖdzania modelami AI - sprawdzanie statusu, czyszczenie, wymuszanie retreningu.
"""

import os
import sys
import json
import time
import logging
import argparse
import shutil
from datetime import datetime

# Konfiguracja logowania
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('logs/ai_models_management.log'),
        logging.StreamHandler()
    ]
)

# Upewnij siƒô, ≈ºe katalog log√≥w istnieje
os.makedirs('logs', exist_ok=True)

def list_models():
    """Wy≈õwietla listƒô dostƒôpnych modeli."""
    models_dir = 'models'
    if not os.path.exists(models_dir):
        print("Katalog modeli nie istnieje!")
        return

    model_files = [f for f in os.listdir(models_dir) if f.endswith('_model.pkl')]
    
    if not model_files:
        print("Brak zapisanych modeli.")
        return
    
    print(f"\nZnaleziono {len(model_files)} modeli:\n")
    
    for model_file in model_files:
        model_name = model_file.replace('_model.pkl', '')
        model_path = os.path.join(models_dir, model_file)
        
        # Podstawowe informacje o pliku
        size_kb = os.path.getsize(model_path) / 1024
        modified_time = datetime.fromtimestamp(os.path.getmtime(model_path))
        
        # Sprawd≈∫ czy istniejƒÖ metadane
        metadata_path = os.path.join(models_dir, f"{model_name}_metadata.json")
        metadata_info = ""
        
        if os.path.exists(metadata_path):
            try:
                with open(metadata_path, 'r') as f:
                    metadata = json.load(f)
                
                if isinstance(metadata, dict) and 'accuracy' in metadata:
                    metadata_info = f", Dok≈Çadno≈õƒá: {metadata['accuracy']:.2f}"
                elif isinstance(metadata, dict) and 'version' in metadata:
                    metadata_info = f", Wersja: {metadata['version']}"
            except json.JSONDecodeError:
                metadata_info = " (B≈ÇƒÖd odczytu metadanych)"
        
        print(f"- {model_name:<20} | {size_kb:6.1f} KB | {modified_time.strftime('%Y-%m-%d %H:%M:%S')}{metadata_info}")

def clean_models(force=False):
    """Czy≈õci uszkodzone i niepe≈Çne modele."""
    models_dir = 'models'
    if not os.path.exists(models_dir):
        print("Katalog modeli nie istnieje!")
        return
    
    model_files = [f for f in os.listdir(models_dir) if f.endswith('_model.pkl')]
    metadata_files = [f for f in os.listdir(models_dir) if f.endswith('_metadata.json')]
    
    # Wykrywanie uszkodzonych plik√≥w modeli
    removed_count = 0
    for model_file in model_files:
        model_path = os.path.join(models_dir, model_file)
        
        # Sprawd≈∫ czy plik jest pusty lub uszkodzony
        if os.path.getsize(model_path) == 0:
            if force or input(f"Model {model_file} jest pusty. UsunƒÖƒá? [t/N]: ").lower() == 't':
                os.remove(model_path)
                print(f"Usuniƒôto pusty model: {model_file}")
                removed_count += 1
        else:
            # Test wczytania modelu
            try:
                import pickle
                with open(model_path, 'rb') as f:
                    # Pr√≥ba wczytania tylko nag≈Ç√≥wka pliku pickle
                    pickle.load(f)
            except (pickle.UnpicklingError, EOFError, AttributeError) as e:
                if force or input(f"Model {model_file} jest uszkodzony ({str(e)}). UsunƒÖƒá? [t/N]: ").lower() == 't':
                    os.remove(model_path)
                    print(f"Usuniƒôto uszkodzony model: {model_file}")
                    removed_count += 1
    
    # Sprawd≈∫ czy sƒÖ niepasujƒÖce pliki metadanych
    for metadata_file in metadata_files:
        model_name = metadata_file.replace('_metadata.json', '')
        model_file = f"{model_name}_model.pkl"
        
        if model_file not in model_files:
            if force or input(f"Plik metadanych {metadata_file} nie ma odpowiadajƒÖcego modelu. UsunƒÖƒá? [t/N]: ").lower() == 't':
                os.remove(os.path.join(models_dir, metadata_file))
                print(f"Usuniƒôto osierocony plik metadanych: {metadata_file}")
                removed_count += 1
    
    print(f"\nCzyszczenie zako≈Ñczone. Usuniƒôto {removed_count} plik√≥w.")

def backup_models():
    """Tworzy kopiƒô zapasowƒÖ modeli."""
    models_dir = 'models'
    if not os.path.exists(models_dir):
        print("Katalog modeli nie istnieje!")
        return
    
    # Utw√≥rz katalog backupu z timestampem
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    backup_dir = f"models_backup_{timestamp}"
    os.makedirs(backup_dir, exist_ok=True)
    
    # Kopiuj wszystkie pliki modeli
    model_files = [f for f in os.listdir(models_dir) if f.endswith(('_model.pkl', '_metadata.json'))]
    
    if not model_files:
        print("Brak modeli do backupu!")
        os.rmdir(backup_dir)
        return
    
    for file in model_files:
        src_path = os.path.join(models_dir, file)
        dst_path = os.path.join(backup_dir, file)
        shutil.copy2(src_path, dst_path)
    
    print(f"Utworzono backup {len(model_files)} plik√≥w w katalogu {backup_dir}")

def test_models():
    """Testuje wszystkie modele."""
    print("Uruchamianie test√≥w modeli...")
    
    # Importuj tester modeli
    try:
        sys.path.insert(0, os.getcwd())
        from python_libs.model_tester import ModelTester
        
        # Inicjalizacja testera modeli
        tester = ModelTester(models_path='ai_models', log_path='logs/model_tests.log')
        
        # ≈Åadowanie i testowanie modeli
        loaded_models = tester.load_models()
        
        print(f"\nZa≈Çadowano {len(loaded_models)} modeli\n")
        
        # Przeprowad≈∫ testy
        success_count = 0
        for model_info in loaded_models:
            model_name = model_info.get('name', 'Nieznany model')
            model_instance = model_info.get('instance')
            
            if model_instance:
                print(f"Testowanie modelu: {model_name}")
                result = tester.test_model(model_instance, model_name)
                if result:
                    success_count += 1
                    print(f"  ‚úÖ Sukces")
                else:
                    print(f"  ‚ùå B≈ÇƒÖd")
            else:
                print(f"Nie uda≈Ço siƒô za≈Çadowaƒá modelu: {model_name}")
        
        print(f"\nWyniki test√≥w: {success_count}/{len(loaded_models)} modeli przesz≈Ço testy")
        
    except ImportError as e:
        print(f"Nie mo≈ºna zaimportowaƒá testera modeli: {e}")
        print("Uruchom test_models.py w celu pe≈Çnego testowania.")

def main():
    """G≈Ç√≥wna funkcja skryptu."""
    parser = argparse.ArgumentParser(description="ZarzƒÖdzanie modelami AI")
    
    subparsers = parser.add_subparsers(dest='command', help='Polecenie do wykonania')
    
    # Polecenie list
    list_parser = subparsers.add_parser('list', help='Wy≈õwietl listƒô modeli')
    
    # Polecenie clean
    clean_parser = subparsers.add_parser('clean', help='Usu≈Ñ uszkodzone modele')
    clean_parser.add_argument('--force', action='store_true', help='Usu≈Ñ bez potwierdzenia')
    
    # Polecenie backup
    backup_parser = subparsers.add_parser('backup', help='Utw√≥rz kopiƒô zapasowƒÖ modeli')
    
    # Polecenie test
    test_parser = subparsers.add_parser('test', help='Testuj modele')
    
    args = parser.parse_args()
    
    if args.command == 'list':
        list_models()
    elif args.command == 'clean':
        clean_models(args.force)
    elif args.command == 'backup':
        backup_models()
    elif args.command == 'test':
        test_models()
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
